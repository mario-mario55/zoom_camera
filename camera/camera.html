<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>顔ズームカメラ（クロスフェード付き）</title>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; background: black; }
    video, canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 640px;
      height: 480px;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>
  <audio id="bgm" src="bgm.mp3" loop></audio>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const bgm = document.getElementById('bgm');

    let state = 'idle'; // idle | zooming | locked
    let faceBox = null;
    let zoom = 1.0;
    let zoomTarget = 2.5;
    let zoomDuration = 3000;
    let zoomStartTime = null;

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models/tiny_face_detector');
    }

    async function startCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      await new Promise(resolve => video.onloadedmetadata = resolve);
    }

    async function detectRandomFace() {
      const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.3 });
      const detections = await faceapi.detectAllFaces(video, options);
      if (detections.length === 0) return null;
      const randomIndex = Math.floor(Math.random() * detections.length);
      return detections[randomIndex].box;
    }

    function startZoom(box) {
      faceBox = box;
      zoom = 1.0;
      zoomStartTime = performance.now();
      state = 'zooming';
      bgm.currentTime = 0;
      bgm.play();
    }

    function renderZoomedVideo(currentZoom, alpha = 1.0) {
      const { x, y, width, height } = faceBox;
      ctx.save();
      ctx.globalAlpha = alpha;
      ctx.drawImage(
        video,
        x, y, width, height,
        canvas.width / 2 - (width * currentZoom) / 2,
        canvas.height / 2 - (height * currentZoom) / 2,
        width * currentZoom,
        height * currentZoom
      );
      ctx.restore();
    }

    function render(timestamp) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      if (state === 'idle') {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      } else if (state === 'zooming') {
        const elapsed = timestamp - zoomStartTime;
        const t = Math.min(elapsed / zoomDuration, 1.0);
        zoom = 1.0 + (zoomTarget - 1.0) * easeInOutQuad(t);

        // 背景（通常映像）
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // 上にズーム映像をクロスフェード
        renderZoomedVideo(zoom, t); // 透明度tでクロスフェード

        if (t >= 1.0) {
          state = 'locked';
          bgm.pause();
        }
      } else if (state === 'locked') {
        renderZoomedVideo(zoomTarget);
      }

      requestAnimationFrame(render);
    }

    function easeInOutQuad(t) {
      return t < 0.5 ? 2 * t * t : -1 + (4 - 2 * t) * t;
    }

    canvas.addEventListener('click', async () => {
      if (state === 'idle') {
        const face = await detectRandomFace();
        if (face) startZoom(face);
      } else if (state === 'locked') {
        state = 'idle';
        bgm.pause();
      }
    });

    window.addEventListener('load', async () => {
      await loadModels();
      await startCamera();
      render();
    });
  </script>
</body>
</html>
