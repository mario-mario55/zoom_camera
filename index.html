<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>顔検出カメラ（ズーム対応＋カメラ切替）</title>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <style>
    body { margin: 0; padding: 0; overflow: hidden; background: black; }
    video, canvas {
      position: absolute; top: 0; left: 0;
      width: 100vw; height: 100vh;
      object-fit: cover;
    }
    #switchBtn {
      position: fixed;
      top: 10px;
      left: 10px;
      z-index: 10;
      padding: 8px 16px;
      font-size: 16px;
      cursor: pointer;
      background: rgba(0,0,0,0.5);
      color: white;
      border: none;
      border-radius: 4px;
    }
  </style>
</head>
<body>
  <button id="switchBtn">カメラ切替</button>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const switchBtn = document.getElementById('switchBtn');

    let state = 'idle'; // idle, zooming, locked
    let faceBox = null;
    let zoom = 1;
    let zoomTarget = 2.5;
    let zoomDuration = 3000;
    let zoomStartTime = null;

    let stream = null;
    let videoDevices = [];
    let currentDeviceIndex = 0;
    let cachedFaces = [];

    async function getVideoDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      videoDevices = devices.filter(device => device.kind === 'videoinput');
    }

 async function setupCamera(deviceId) {
  if (stream) {
    stream.getTracks().forEach(track => track.stop());
  }

  const constraints = {
    video: {
      deviceId: deviceId ? { exact: deviceId } : undefined,
      width: { ideal: 640 }, // 解像度制限
      height: { ideal: 480 }
    }
  };

  try {
    stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    return new Promise(resolve => {
      video.onloadedmetadata = () => resolve(video);
    });
  } catch (err) {
    console.error("カメラ起動エラー:", err);
  }
}


      stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;
      return new Promise(resolve => {
        video.onloadedmetadata = () => resolve(video);
      });
    }

    async function loadModels() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('./models/tiny_face_detector');
      console.log('モデル読み込み完了');
    }

    function scaleBox(box, scaleX, scaleY) {
      return {
        x: box.x * scaleX,
        y: box.y * scaleY,
        width: box.width * scaleX,
        height: box.height * scaleY
      };
    }

    async function detectAllFaces() {
      const options = new faceapi.TinyFaceDetectorOptions();
      return await faceapi.detectAllFaces(video, options);
    }

    async function detectRandomFace() {
      const detections = await detectAllFaces();
      if (detections.length === 0) return null;
      const idx = Math.floor(Math.random() * detections.length);
      return detections[idx].box;
    }

    function startZoom(box) {
      faceBox = box;
      zoom = 1;
      zoomStartTime = performance.now();
      state = 'zooming';
    }

    function easeInOutQuad(t) {
      return t < 0.5 ? 2 * t * t : -1 + (4 - 2 * t) * t;
    }

    function render(timestamp = performance.now()) {
      const vw = video.videoWidth;
      const vh = video.videoHeight;
      const cw = canvas.width = window.innerWidth;
      const ch = canvas.height = window.innerHeight;
      const scaleX = cw / vw;
      const scaleY = ch / vh;

      ctx.clearRect(0, 0, cw, ch);
      ctx.drawImage(video, 0, 0, cw, ch);

      if (state === 'idle') {
        cachedFaces.forEach(f => {
          const box = scaleBox(f.box, scaleX, scaleY);
          ctx.strokeStyle = 'lime';
          ctx.lineWidth = 2;
          ctx.strokeRect(box.x, box.y, box.width, box.height);
        });
      } else if (state === 'zooming' || state === 'locked') {
        const b = scaleBox(faceBox, scaleX, scaleY);
        const t = state === 'zooming' ? Math.min((timestamp - zoomStartTime) / zoomDuration, 1) : 1;
        zoom = 1 + (zoomTarget - 1) * easeInOutQuad(t);

        const zx = cw / 2 - (b.width * zoom) / 2;
        const zy = ch / 2 - (b.height * zoom) / 2;

        ctx.drawImage(video,
          b.x / scaleX, b.y / scaleY, b.width / scaleX, b.height / scaleY,
          zx, zy, b.width * zoom, b.height * zoom);

        ctx.strokeStyle = 'red';
        ctx.lineWidth = 3;
        ctx.strokeRect(zx, zy, b.width * zoom, b.height * zoom);

        if (state === 'zooming' && t >= 1) {
          state = 'locked';
        }
      }

      requestAnimationFrame(render);
    }

    async function updateFacesPeriodically() {
      while (true) {
        if (state === 'idle') {
          cachedFaces = await detectAllFaces();
        }
        await new Promise(r => setTimeout(r, 500));
      }
    }

    canvas.addEventListener('click', async () => {
      if (state === 'idle') {
        const face = await detectRandomFace();
        if (face) startZoom(face);
      } else if (state === 'locked') {
        state = 'idle';
      }
    });

    switchBtn.addEventListener('click', async () => {
      if (videoDevices.length < 2) {
        alert('カメラが2台以上検出されませんでした');
        return;
      }
      currentDeviceIndex = (currentDeviceIndex + 1) % videoDevices.length;
      await setupCamera(videoDevices[currentDeviceIndex].deviceId);
    });

    async function main() {
      await loadModels();
      await getVideoDevices();
      if (videoDevices.length === 0) {
        alert('カメラが見つかりません');
        return;
      }
      await setupCamera(videoDevices[currentDeviceIndex].deviceId);
      video.play();
      updateFacesPeriodically();
      render();
    }

    main();
  </script>
</body>
</html>
